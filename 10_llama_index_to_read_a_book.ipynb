{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index\n",
    "%pip install langchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先搜索，后提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 6770 tokens\n"
     ]
    }
   ],
   "source": [
    "import openai, os\n",
    "from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "documents = SimpleDirectoryReader('./data/mr_fujino').load_data()\n",
    "index = GPTSimpleVectorIndex.from_documents(documents)\n",
    "\n",
    "index.save_to_disk('index_mr_fujino.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 2991 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 34 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "鲁迅先生在日本学习医学的老师是藤野严九郎先生。\n"
     ]
    }
   ],
   "source": [
    "index = GPTSimpleVectorIndex.load_from_disk('index_mr_fujino.json')\n",
    "response = index.query(\"鲁迅先生在日本学习医学的老师是谁？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m> Got node text: 藤野先生\n",
      "\n",
      "鲁迅\n",
      "\n",
      "东京也无非是这样。上野的樱花烂熳的时节，望去确也像绯红的轻云，但花下也缺不了成群结队的“清国留学生”的速成班，头顶上盘着大辫子，顶得学生制帽的顶上高高耸起，形成一座富士山。也有解散辫子，盘得平的，除下帽来，油光可鉴，宛如小姑娘的发髻一般，还要将脖子扭几扭。实在标致极了。\n",
      "\n",
      "中国留学生会馆的门房里有几本书买，有时还值得去一转；倘在上午，里面的几间洋房里倒也还可以坐坐的。但到...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 2975 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 25 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "鲁迅先生去仙台的医学专门学校学习医学。\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"鲁迅先生去哪里学的医学？\", verbose=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m> Got node text: 藤野先生\n",
      "\n",
      "鲁迅\n",
      "\n",
      "东京也无非是这样。上野的樱花烂熳的时节，望去确也像绯红的轻云，但花下也缺不了成群结队的“清国留学生”的速成班，头顶上盘着大辫子，顶得学生制帽的顶上高高耸起，形成一座富士山。也有解散辫子，盘得平的，除下帽来，油光可鉴，宛如小姑娘的发髻一般，还要将脖子扭几扭。实在标致极了。\n",
      "\n",
      "中国留学生会馆的门房里有几本书买，有时还值得去一转；倘在上午，里面的几间洋房里倒也还可以坐坐的。但到...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3014 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 25 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "不知道\n"
     ]
    }
   ],
   "source": [
    "from llama_index import QuestionAnswerPrompt\n",
    "query_str = \"鲁迅先生去哪里学的医学？\"\n",
    "QA_PROMPT_TMPL = (\n",
    "    \"下面的“我”指的是鲁迅先生 \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"根据这些信息，请回答问题: {query_str}\\n\"\n",
    "    \"如果您不知道的话，请回答不知道\\n\"\n",
    ")\n",
    "QA_PROMPT = QuestionAnswerPrompt(QA_PROMPT_TMPL)\n",
    "# Build GPTSimpleVectorIndex\n",
    "\n",
    "response = index.query(query_str, text_qa_template=QA_PROMPT, verbose=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 3027 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 37 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "不知道\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"请问林黛玉和贾宝玉是什么关系？\", text_qa_template=QA_PROMPT)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过llama_index对于文章进行小结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy\n",
    "%python -m spacy download zh_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.llm_predictor.base:Unknown max input size for gpt-3.5-turbo, using defaults.\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 2 chunks\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 9787 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲁迅先生回忆了自己在日本学医期间的经历，描述了自己在解剖实习中的经历，以及与教授藤野先生的交往。他还提到了一些不愉快的事情，比如遭到同学的诽谤和歧视，以及看到中国人被枪毙时的感受。最后，他告诉藤野先生自己将不再学医，而是想学生物学。他想起了一个人，这个人是他的老师，他对鲁迅很热心，给他很多鼓励和教诲。鲁迅现在只有他的照片，但是每次看到他的照片，都会让他感到勇气和良心发现。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from llama_index import GPTListIndex, LLMPredictor, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "# define LLM\n",
    "llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=1024))\n",
    "\n",
    "text_splitter = SpacyTextSplitter(pipeline=\"zh_core_web_sm\", chunk_size = 2048)\n",
    "parser = SimpleNodeParser(text_splitter=text_splitter)\n",
    "documents = SimpleDirectoryReader('./data/mr_fujino').load_data()\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "\n",
    "list_index = GPTListIndex(nodes=nodes, service_context=service_context)\n",
    "response = list_index.query(\"下面鲁迅先生以第一人称‘我’写的内容，请你用中文总结一下:\", response_mode=\"tree_summarize\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.indices.query.tree.summarize_query:> Starting query: 下面鲁迅先生以第一人称‘我’写的内容，请你用中文总结一下:\n",
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 2 chunks\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 9653 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲁迅先生回忆了自己在日本学医的经历，描述了自己在解剖实习中遇到的困难和藤野先生的态度，以及自己在学校中遭受的歧视和流言。最后，他告诉藤野先生自己不再学医，离开仙台，并且与藤野先生告别。他想写信给一个老师，但不知道该写些什么。这个老师的名字不为人所知，但他的性格很伟大。鲁迅现在只有他的照片，但每次看到照片都会让他感到勇气和良心发现。\n"
     ]
    }
   ],
   "source": [
    "from llama_index import GPTTreeIndex\n",
    "\n",
    "# define LLM\n",
    "tree_index = GPTTreeIndex(nodes=nodes, service_context=service_context)\n",
    "response = tree_index.query(\"下面鲁迅先生以第一人称‘我’写的内容，请你用中文总结一下:\", mode=\"summarize\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持图片的多模态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8114e84f04cf14e493992e1b725447accf84073d5ec18e7063d492738bf032cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
