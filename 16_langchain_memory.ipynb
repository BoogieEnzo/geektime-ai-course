{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transfered to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 我是一个中国厨师，您有什么可以问我的关于做菜的问题吗？\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "SUMMARIZER_TEMPLATE = \"\"\"请将以下内容逐步概括所提供的对话内容，并将新的概括添加到之前的概括中，形成新的概括。\n",
    "\n",
    "EXAMPLE\n",
    "Current summary:\n",
    "Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量。\n",
    "\n",
    "New lines of conversation:\n",
    "Human：为什么你认为人工智能是一种积极的力量？\n",
    "AI：因为人工智能将帮助人类发挥他们的潜能。\n",
    "\n",
    "New summary:\n",
    "Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量，因为它将帮助人类发挥他们的潜能。\n",
    "END OF EXAMPLE\n",
    "\n",
    "Current summary:\n",
    "{summary}\n",
    "\n",
    "New lines of conversation:\n",
    "{new_lines}\n",
    "\n",
    "New summary:\"\"\"\n",
    "\n",
    "SUMMARY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"summary\", \"new_lines\"], template=SUMMARIZER_TEMPLATE\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=OpenAI(), prompt=SUMMARY_PROMPT, max_token_limit=256)\n",
    "\n",
    "CHEF_TEMPLATE = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文。\n",
    "2. 对于做菜步骤的回答尽量详细一些。\n",
    "\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "CHEF_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=CHEF_TEMPLATE\n",
    ")\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=OpenAI(model_name=\"text-davinci-003\", stop=\"\\n\\n\", max_tokens=2048, temperature=0.5), \n",
    "    prompt=CHEF_PROMPT,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "answer = conversation_with_summary.predict(input=\"你是谁？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:  我是一个中国厨师，您有什么可以问我的关于做菜的问题吗？\n",
      "Human: 请问鱼香肉丝怎么做？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 鱼香肉丝是一道很受欢迎的中国菜，准备材料有：猪肉、木耳、胡萝卜、葱姜蒜、花椒、八角、辣椒、料酒、糖、盐、醋、麻油、香油。做法步骤如下：1. 将猪肉切成薄片，用料酒、盐、糖、醋、麻油抓匀；2. 将木耳洗净，切碎；3. 将胡萝卜切丝；4. 将葱姜蒜切碎；5. 将花椒、八角、辣椒放入油锅中炸熟；6. 将葱姜蒜炒香；7. 加入猪肉片翻炒；8. 加入木耳、胡萝卜丝、花椒、八角、辣椒翻炒；9. 加入盐、糖、醋、麻油、香油调味；10. 加入水煮熟，即可出锅。\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_summary.predict(input=\"请问鱼香肉丝怎么做？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "System: \n",
      "Human询问AI是谁，AI回答自己是一个中国厨师，并问Human是否有关于做菜的问题。Human问AI如何做出鱼香肉丝，AI回答准备材料有猪肉、木耳、胡萝卜、葱姜蒜、花椒、八角、辣椒、料酒、糖、盐、醋、麻油、香油，做法步骤是将猪肉切成薄片，用料酒、盐、糖、醋、麻油抓匀，木耳\n",
      "Human: 那蚝油牛肉呢？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 准备材料有牛肉、葱、姜、蒜、蚝油、料酒、醋、糖、盐、香油，做法步骤是先将牛肉切成薄片，用料酒、盐、糖、醋、麻油抓匀，然后将葱、姜、蒜切碎，加入蚝油拌匀，最后加入香油搅拌均匀即可。\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_summary.predict(input=\"那蚝油牛肉呢？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "System: \n",
      "Human询问AI是谁，AI回答自己是一个中国厨师，并问Human是否有关于做菜的问题。Human问AI如何做出鱼香肉丝，AI回答准备材料有猪肉、木耳、胡萝卜、葱姜蒜、花椒、八角、辣椒、料酒、糖、盐、醋、麻油、香油，做法步骤是将猪肉切成薄片，用料酒、盐、糖、醋、麻油抓匀，木耳\n",
      "Human: 那蚝油牛肉呢？\n",
      "AI:  准备材料有牛肉、葱、姜、蒜、蚝油、料酒、醋、糖、盐、香油，做法步骤是先将牛肉切成薄片，用料酒、盐、糖、醋、麻油抓匀，然后将葱、姜、蒜切碎，加入蚝油拌匀，最后加入香油搅拌均匀即可。\n",
      "Human: 宫保鸡丁和软炸里脊哪个好吃？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 这两道菜都很好吃，但是宫保鸡丁更具有特色，它是一道著名的川菜，它的特点是酸甜口味，配上香辣的花椒，而软炸里脊则是一道比较清淡的菜，口感柔软，配上酱汁更加美味。\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_summary.predict(input=\"宫保鸡丁和软炸里脊哪个好吃？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 宫保鸡丁和软炸里脊哪个好吃？\\nAI:  这两道菜都很好吃，但是宫保鸡丁更具有特色，它是一道著名的川菜，它的特点是酸甜口味，配上香辣的花椒，而软炸里脊则是一道比较清淡的菜，口感柔软，配上酱汁更加美味。'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationKGMemory\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template\n",
    ")\n",
    "kg_memory = ConversationKGMemory(llm=llm)\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    prompt=prompt,\n",
    "    memory=kg_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: 你好\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 你好！很高兴见到你。我是一个AI，我可以回答你的问题。你想问我什么？\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: 我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 嗨徐文浩，很高兴认识你！我看到你的订单号是2023ABCD，你的邮箱地址是customer@abc.com。我确认你的订单，但是没有收到货，对吗？\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_kg.predict(input=\"你好\")\n",
    "print(answer)\n",
    "answer = conversation_with_kg.predict(input=\"我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseModel.json of ConversationKGMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='你好', additional_kwargs={}), AIMessage(content=' 你好！很高兴见到你。我是一个AI，我可以回答你的问题。你想问我什么？', additional_kwargs={}), HumanMessage(content='我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货', additional_kwargs={}), AIMessage(content=' 嗨徐文浩，很高兴认识你！我看到你的订单号是2023ABCD，你的邮箱地址是customer@abc.com。我确认你的订单，但是没有收到货，对吗？', additional_kwargs={})]), output_key=None, input_key=None, return_messages=False, k=2, human_prefix='Human', ai_prefix='AI', kg=<langchain.graphs.networkx_graph.NetworkxEntityGraph object at 0x7f8b39506b90>, knowledge_extraction_prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template=\"You are a networked intelligence helping a human track knowledge triples about all relevant people, things, concepts, etc. and integrating them with your knowledge stored within your weights as well as that stored in a knowledge graph. Extract all of the knowledge triples from the last line of conversation. A knowledge triple is a clause that contains a subject, a predicate, and an object. The subject is the entity being described, the predicate is the property of the subject that is being described, and the object is the value of the property.\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: Did you hear aliens landed in Area 51?\\nAI: No, I didn't hear that. What do you know about Area 51?\\nPerson #1: It's a secret military base in Nevada.\\nAI: What do you know about Nevada?\\nLast line of conversation:\\nPerson #1: It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\nOutput: (Nevada, is a, state)<|>(Nevada, is in, US)<|>(Nevada, is the number 1 producer of, gold)\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: Hello.\\nAI: Hi! How are you?\\nPerson #1: I'm good. How are you?\\nAI: I'm good too.\\nLast line of conversation:\\nPerson #1: I'm going to the store.\\n\\nOutput: NONE\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: What do you know about Descartes?\\nAI: Descartes was a French philosopher, mathematician, and scientist who lived in the 17th century.\\nPerson #1: The Descartes I'm referring to is a standup comedian and interior designer from Montreal.\\nAI: Oh yes, He is a comedian and an interior designer. He has been in the industry for 30 years. His favorite food is baked bean pie.\\nPerson #1: Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\nLast line of conversation:\\nOutput: (Descartes, likes to drive, antique scooters)<|>(Descartes, plays, mandolin)\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:\", template_format='f-string', validate_template=True), entity_extraction_prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \"What do you know about him\" where \"him\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I\\'m working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7f8ab82da440>, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False), memory_key='history')>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.memory.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 您好，张老三，我很抱歉你没有收到货。我们会尽快核实订单信息，并尽快给您处理，请您耐心等待，如果有任何疑问，欢迎您随时联系我们。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "entityMemory = ConversationEntityMemory(llm=llm)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=entityMemory\n",
    ")\n",
    "\n",
    "answer=conversation.predict(input=\"我叫张老三，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是这个订单十几天了还没有收到货\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'张老三': '张老三是一位订单号为2023ABCD、邮箱地址为customer@abc.com的客户。', '2023ABCD': '2023ABCD is an order placed by customer@abc.com that has not been received after more than ten days.', 'customer@abc.com': 'Email address of Zhang Lao San, who placed an order with Order Number 2023ABCD, but has not received the goods more than ten days later.'}\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: \\nHuman和AI打招呼，AI介绍自己是客服李四，问Human有什么可以帮助的。Human提供订单号和邮箱地址，AI表示会为其查询订单状态。'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=OpenAI(), prompt=SUMMARY_PROMPT, max_token_limit=40)\n",
    "memory.save_context(\n",
    "    {\"input\": \"你好\"}, \n",
    "    {\"ouput\": \"你好，我是客服李四，有什么我可以帮助您的么\"}\n",
    "    )\n",
    "memory.save_context(\n",
    "    {\"input\": \"我叫张三，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是这个订单十几天了还没有收到货\"}, \n",
    "    {\"ouput\": \"好的，您稍等，我先为您查询一下您的订单\"}\n",
    "    )\n",
    "memory.load_memory_variables({})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
